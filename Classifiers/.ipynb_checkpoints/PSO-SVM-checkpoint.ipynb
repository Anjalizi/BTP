{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('parkinsons.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.drop(columns=['name', 'status'])\n",
    "# y = data['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.655084</td>\n",
       "      <td>-2.128963</td>\n",
       "      <td>-0.685016</td>\n",
       "      <td>1.922747</td>\n",
       "      <td>0.645288</td>\n",
       "      <td>-2.224576</td>\n",
       "      <td>1.198653</td>\n",
       "      <td>-1.442570</td>\n",
       "      <td>0.225801</td>\n",
       "      <td>1.922747</td>\n",
       "      <td>2.454673</td>\n",
       "      <td>1.198653</td>\n",
       "      <td>0.884753</td>\n",
       "      <td>-0.601173</td>\n",
       "      <td>0.918193</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.303401</td>\n",
       "      <td>-1.378328</td>\n",
       "      <td>-0.566002</td>\n",
       "      <td>0.114298</td>\n",
       "      <td>-0.239843</td>\n",
       "      <td>-0.310322</td>\n",
       "      <td>1.501327</td>\n",
       "      <td>-0.044018</td>\n",
       "      <td>-0.472958</td>\n",
       "      <td>0.114298</td>\n",
       "      <td>0.492101</td>\n",
       "      <td>1.501327</td>\n",
       "      <td>-0.494118</td>\n",
       "      <td>-0.512464</td>\n",
       "      <td>0.141817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.724706</td>\n",
       "      <td>-0.986521</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>-1.895799</td>\n",
       "      <td>0.042914</td>\n",
       "      <td>0.472371</td>\n",
       "      <td>-0.318019</td>\n",
       "      <td>0.951178</td>\n",
       "      <td>0.644809</td>\n",
       "      <td>-1.895799</td>\n",
       "      <td>0.418651</td>\n",
       "      <td>-0.318019</td>\n",
       "      <td>-0.271892</td>\n",
       "      <td>-2.731398</td>\n",
       "      <td>0.936142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049146</td>\n",
       "      <td>-0.588923</td>\n",
       "      <td>0.326328</td>\n",
       "      <td>0.922614</td>\n",
       "      <td>1.131195</td>\n",
       "      <td>-0.983339</td>\n",
       "      <td>0.549084</td>\n",
       "      <td>1.621353</td>\n",
       "      <td>1.479451</td>\n",
       "      <td>0.922614</td>\n",
       "      <td>-0.951512</td>\n",
       "      <td>0.549084</td>\n",
       "      <td>-0.470488</td>\n",
       "      <td>0.787868</td>\n",
       "      <td>-0.696832</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.378306</td>\n",
       "      <td>-1.327988</td>\n",
       "      <td>0.647906</td>\n",
       "      <td>0.877558</td>\n",
       "      <td>-1.091076</td>\n",
       "      <td>-1.513970</td>\n",
       "      <td>1.208688</td>\n",
       "      <td>-0.459604</td>\n",
       "      <td>1.786182</td>\n",
       "      <td>0.877558</td>\n",
       "      <td>-1.650467</td>\n",
       "      <td>1.208688</td>\n",
       "      <td>-0.393068</td>\n",
       "      <td>1.295161</td>\n",
       "      <td>-0.512984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.177226</td>\n",
       "      <td>2.043693</td>\n",
       "      <td>1.136525</td>\n",
       "      <td>0.267609</td>\n",
       "      <td>-0.840022</td>\n",
       "      <td>2.573524</td>\n",
       "      <td>-0.365685</td>\n",
       "      <td>-1.487846</td>\n",
       "      <td>-0.479539</td>\n",
       "      <td>0.267609</td>\n",
       "      <td>-0.702859</td>\n",
       "      <td>-0.365685</td>\n",
       "      <td>1.137251</td>\n",
       "      <td>-1.456116</td>\n",
       "      <td>0.617562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.540818</td>\n",
       "      <td>-0.568785</td>\n",
       "      <td>0.470516</td>\n",
       "      <td>2.667254</td>\n",
       "      <td>-0.087918</td>\n",
       "      <td>-3.171549</td>\n",
       "      <td>-1.952123</td>\n",
       "      <td>-1.275209</td>\n",
       "      <td>-0.458240</td>\n",
       "      <td>2.667254</td>\n",
       "      <td>1.099393</td>\n",
       "      <td>-1.952123</td>\n",
       "      <td>-0.022824</td>\n",
       "      <td>-0.656279</td>\n",
       "      <td>-1.181429</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.671385</td>\n",
       "      <td>-0.336407</td>\n",
       "      <td>0.563321</td>\n",
       "      <td>1.780646</td>\n",
       "      <td>0.784192</td>\n",
       "      <td>-0.075812</td>\n",
       "      <td>0.302305</td>\n",
       "      <td>0.317170</td>\n",
       "      <td>-0.217989</td>\n",
       "      <td>1.780646</td>\n",
       "      <td>-0.837611</td>\n",
       "      <td>0.302305</td>\n",
       "      <td>0.572541</td>\n",
       "      <td>-2.339250</td>\n",
       "      <td>-0.068524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.917319</td>\n",
       "      <td>-0.306018</td>\n",
       "      <td>1.849917</td>\n",
       "      <td>-0.225949</td>\n",
       "      <td>0.609191</td>\n",
       "      <td>1.034543</td>\n",
       "      <td>1.791212</td>\n",
       "      <td>0.073941</td>\n",
       "      <td>0.314464</td>\n",
       "      <td>-0.225949</td>\n",
       "      <td>-0.253615</td>\n",
       "      <td>1.791212</td>\n",
       "      <td>0.297657</td>\n",
       "      <td>0.307610</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.477501</td>\n",
       "      <td>1.627130</td>\n",
       "      <td>-1.234006</td>\n",
       "      <td>1.430260</td>\n",
       "      <td>-0.636191</td>\n",
       "      <td>0.975214</td>\n",
       "      <td>-0.163108</td>\n",
       "      <td>-0.637353</td>\n",
       "      <td>-0.297395</td>\n",
       "      <td>1.430260</td>\n",
       "      <td>-0.049065</td>\n",
       "      <td>-0.163108</td>\n",
       "      <td>-0.494582</td>\n",
       "      <td>0.482936</td>\n",
       "      <td>-2.009301</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0   0.655084 -2.128963 -0.685016  1.922747  0.645288 -2.224576  1.198653   \n",
       "1  -0.303401 -1.378328 -0.566002  0.114298 -0.239843 -0.310322  1.501327   \n",
       "2   0.724706 -0.986521  0.389249 -1.895799  0.042914  0.472371 -0.318019   \n",
       "3   0.049146 -0.588923  0.326328  0.922614  1.131195 -0.983339  0.549084   \n",
       "4   0.378306 -1.327988  0.647906  0.877558 -1.091076 -1.513970  1.208688   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -0.177226  2.043693  1.136525  0.267609 -0.840022  2.573524 -0.365685   \n",
       "96  0.540818 -0.568785  0.470516  2.667254 -0.087918 -3.171549 -1.952123   \n",
       "97  0.671385 -0.336407  0.563321  1.780646  0.784192 -0.075812  0.302305   \n",
       "98  1.917319 -0.306018  1.849917 -0.225949  0.609191  1.034543  1.791212   \n",
       "99  1.477501  1.627130 -1.234006  1.430260 -0.636191  0.975214 -0.163108   \n",
       "\n",
       "           7         8         9        10        11        12        13  \\\n",
       "0  -1.442570  0.225801  1.922747  2.454673  1.198653  0.884753 -0.601173   \n",
       "1  -0.044018 -0.472958  0.114298  0.492101  1.501327 -0.494118 -0.512464   \n",
       "2   0.951178  0.644809 -1.895799  0.418651 -0.318019 -0.271892 -2.731398   \n",
       "3   1.621353  1.479451  0.922614 -0.951512  0.549084 -0.470488  0.787868   \n",
       "4  -0.459604  1.786182  0.877558 -1.650467  1.208688 -0.393068  1.295161   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -1.487846 -0.479539  0.267609 -0.702859 -0.365685  1.137251 -1.456116   \n",
       "96 -1.275209 -0.458240  2.667254  1.099393 -1.952123 -0.022824 -0.656279   \n",
       "97  0.317170 -0.217989  1.780646 -0.837611  0.302305  0.572541 -2.339250   \n",
       "98  0.073941  0.314464 -0.225949 -0.253615  1.791212  0.297657  0.307610   \n",
       "99 -0.637353 -0.297395  1.430260 -0.049065 -0.163108 -0.494582  0.482936   \n",
       "\n",
       "          14  labels  \n",
       "0   0.918193       0  \n",
       "1   0.141817       0  \n",
       "2   0.936142       0  \n",
       "3  -0.696832       2  \n",
       "4  -0.512984       2  \n",
       "..       ...     ...  \n",
       "95  0.617562       2  \n",
       "96 -1.181429       0  \n",
       "97 -0.068524       0  \n",
       "98 -0.000731       1  \n",
       "99 -2.009301       2  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=15, n_classes=3,\n",
    "                           n_informative=4, n_redundant=1, n_repeated=2,\n",
    "                           random_state=1)\n",
    "df = pd.DataFrame(X)\n",
    "df['labels'] = pd.Series(y)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_per_particle(m, alpha):\n",
    "    \"\"\"Computes for the objective function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "    alpha: float (default is 0.5)\n",
    "        Constant weight for trading-off classifier performance\n",
    "        and number of features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function\n",
    "    \"\"\"\n",
    "    total_features = X.shape[1]\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:,m==1]\n",
    "    # Perform classification and store performance in P\n",
    "    classifier.fit(X_subset, y)\n",
    "    P = (classifier.predict(X_subset) == y).mean()\n",
    "    # Compute for the objective function\n",
    "    j = (alpha * (1.0 - P)\n",
    "        + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "\n",
    "    return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, alpha=0.88):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-11 20:01:46,745 - pyswarms.discrete.binary - INFO - Optimize for 1000 iters with {'c1': 0.5, 'c2': 0.5, 'w': 0.9, 'k': 30, 'p': 2}\n",
      "pyswarms.discrete.binary: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|1000/1000, best_cost=0.129\n",
      "2020-05-11 20:02:24,956 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.1288, best pos: [0 1 1 1 1 1 0 1 1 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Initialize swarm, arbitrary\n",
    "options = {'c1': 0.5, 'c2': 0.5, 'w':0.9, 'k': 30, 'p':2}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = X.shape[1] # dimensions should be the number of features\n",
    "\n",
    "optimizer = ps.discrete.BinaryPSO(n_particles=30, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7eb34bd6ff79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Compute performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msubset_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_selected_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Subset performance: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubset_performance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c1' is not defined"
     ]
    }
   ],
   "source": [
    "# Create two instances of LogisticRegression\n",
    "classifier1 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Get the selected features from the final positions\n",
    "X_selected_features = X[:,pos==1]  # subset\n",
    "\n",
    "# Perform classification and store performance in P\n",
    "classifier1.fit(X_selected_features, y)\n",
    "\n",
    "# Compute performance\n",
    "subset_performance = (classifier1.predict(X_selected_features) == y).mean()\n",
    "\n",
    "print('Subset performance: %.3f' % (subset_performance))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
